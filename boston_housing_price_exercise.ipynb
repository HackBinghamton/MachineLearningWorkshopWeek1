{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Boston House-Price Dataset\n",
    "The Boston house-price dataset is one of several datasets included with `sklearn`. It contains 506 samples of houses in the Boston area, with 13 different attributes measured of each (e.g. per capita crime, tax rate, pupil-teacher ratio, etc.), with the 'target' variable being the price of the house.\n",
    "\n",
    "Accessing the data in the Boston house-price dataset is exactly the same as accessing the `digits` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "# ...<more imports/code/whatever>...\n",
    "boston = load_boston()\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(boston.data,\n",
    "                                                boston.target,\n",
    "                                                test_size=0.5,    # Tweak to your liking\n",
    "                                                random_state=42)  # Set random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can come up with a model that will accurately predict the price of a house given its attributes.\n",
    "\n",
    "# Models At Our Disposal\n",
    "`sklearn` comes with a massive variety of models, but they all excel at different tasks. For example, convolutional neural networks are exceptionally good at classifying objects in images, where recurrent neural networks are great at things like generating text that follows grammar rules.\n",
    "\n",
    "There is one large distinction between many models to make. There are *classifiers*, and *regressions*. __Classifiers pick from a list of label options to predict what something is (e.g. apples, oranges), while regressions guess a value on a continuous spectrum (e.g. a number on the Richter scale, *the price of a house*)__\n",
    "\n",
    " - __Classifiers *label* things, e.g.:__\n",
    "    - This is picture of a cat\n",
    "    - This data reminds me of an orange\n",
    "    - This sounds like this person's voice\n",
    " - __Regressions *estimate* things, e.g.:__\n",
    "    - This was probably a 3.5 on the Richter scale\n",
    "    - This stock will grow 5% by tomorrow\n",
    "    - *This house probably cost $100k\n",
    "\n",
    "So, for this dataset, it will be most valid to use a *regression* to predict the prices of the test-case houses.\n",
    "\n",
    "Thankfully, `sklearn` comes with many kinds of regression to help achieve this, like `LinearRegression` (sound familiar?), `Lasso`, `Ridge`, and many more, which can be found at the [official documentation](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "\n",
    "Also fortunately, many of them work the same! Here's the basic form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.<some_model_group> import <ModelOfChoice>\n",
    "\n",
    "#...<load up your data, etc.>...\n",
    "\n",
    "# Create the model\n",
    "model = <ModelOfChoice>()\n",
    "\n",
    "# Train it\n",
    "model.train(xtrain, ytrain)\n",
    "\n",
    "# Check the accuracy (if that is your intention)\n",
    "print(\"<ModelOfChoice> Accuracy:\", str(model.score(xtest, ytest) * 100) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, play around and see what you can find! What models work the best for this dataset? What variables can you tweak to get better results?\n",
    "\n",
    "# Using Tensorflow\n",
    "Just like with the MNIST dataset, we can use a neural network to make predictions here as well!\n",
    "\n",
    "Tensorflow thankfully comes with its own version of the Boston housing dataset, which can be accessed similarly to the MNIST set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "boston = tf.keras.datasets.boston_housing\n",
    "\n",
    "(X_train, Y_train), (X_test, Y_test) = boston.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See what you're able to do! It may take a lot of tweaking (especially with respect to the organization of the data), but the neural network from Part II should work great with this dataset.\n",
    "\n",
    "*(Hint: It may help to tweak some options in the flattening and compiling steps, and to find a different way to measure accuracy...)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
